 databases
show database
show databases
show databases;
show tables;
create database sagnik2u6057;
describe database sagnik2u6057;
use sagnik2u6057;
create table x(a, int);
create table x(a int);
describe sagnik2u6057;
describe database sagnik2u6057;
select * from x;
describe x;
describe formatted x;
use sagnik2u6057;
exit
;
CREATE TABLE nyse_hdfs(
    exchange1 STRING,
    symbol1 STRING,
    ymd STRING,
    price_open FLOAT,
    price_high FLOAT,
    price_low FLOAT,
    price_close FLOAT,
    volume INT,
    price_adj_close FLOAT
)
use ${env:USER};
CREATE TABLE orc_table (
    first_name STRING, 
    last_name STRING
 ) 
 STORED AS ORC;
INSERT INTO orc_table VALUES ('John','Gill');
SELECT * FROM orc_table;
use sagnik2u6057;
CREATE TABLE IF NOT EXISTS u_data( 
        userid INT, 
        movieid INT, 
        rating INT, 
        unixtime TIMESTAMP
    )
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;
LOAD DATA INPATH 'hdfs:///user/sagnik2u6057/u.data' overwrite into table u_data;
exit
;
CREATE DATABASE If NOT EXISTS sagnik2u6057;
use sagnik2u6057;
CREATE TABLE IF NOT EXISTS u_data( 
        userid INT, 
        movieid INT, 
        rating INT, 
        unixtime TIMESTAMP
    )
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'
    STORED AS TEXTFILE;
    LOAD DATA INPATH 'hdfs:///user/YOUR_USER_NAME/u.data' overwrite into table u_data;
LOAD DATA INPATH 'hdfs:///user/sagnik2u6057/u.data' overwrite into table u_data;
exit;
ADD JAR hdfs:///data/hive/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar;
SET hive.support.sql11.reserved.keywords=false;
CREATE DATABASE IF NOT EXISTS ${env:USER};
USE ${env:USER};
CREATE EXTERNAL TABLE tweets_raw (
    id BIGINT,
    created_at STRING,
    source STRING,
    favorited BOOLEAN,
    retweet_count INT,
    retweeted_status STRUCT<
    text:STRING,
    users:STRUCT<screen_name:STRING,name:STRING>>,
    entities STRUCT<
    urls:ARRAY<STRUCT<expanded_url:STRING>>,
    user_mentions:ARRAY<STRUCT<screen_name:STRING,name:STRING>>,
    hashtags:ARRAY<STRUCT<text:STRING>>>,
    text STRING,
    user STRUCT<
    screen_name:STRING,
    name:STRING,
    friends_count:INT,
    followers_count:INT,
    statuses_count:INT,
    verified:BOOLEAN,
    utc_offset:STRING, -- was INT but nulls are strings
    time_zone:STRING>,
    in_reply_to_screen_name STRING,
    year int,
    month int,
    day int,
    hour int
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
WITH SERDEPROPERTIES ("ignore.malformed.json" = "true")
LOCATION '/user/${env:USER}/SentimentFiles/SentimentFiles/upload/data/tweets_raw';
SELECT count(id) FROM tweets_raw;
CREATE EXTERNAL TABLE dictionary (
type string,
length int,
word string,
pos string,
stemmed string,
polarity string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE
LOCATION '/user/${env:USER}/SentimentFiles/SentimentFiles/upload/data/dictionary';
describe dictionary;
select count(*) from dictionary;
select polarity from dictionary where word='acridness';
use ${env:USER}
;
CREATE EXTERNAL TABLE time_zone_map (
time_zone string,
country string,
notes string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' 
STORED AS TEXTFILE
LOCATION '/user/${env:USER}/SentimentFiles/SentimentFiles/upload/data/time_zone_map';
select time_zone where country ='FINLAND';
select time_zone from time_zone_map where country ='FINLAND';
CREATE VIEW tweets_simple AS
SELECT          
id,
cast ( from_unixtime( unix_timestamp(concat( '2013 ', substring(created_at,5,15)), 'yyyy MMM dd hh:mm:ss')) as timestamp) ts,
text,
user.time_zone 
FROM tweets_raw;
CREATE VIEW tweets_clean AS
SELECT
id,
ts,
text,
m.country 
FROM tweets_simple t LEFT OUTER JOIN time_zone_map m ON t.time_zone = m.time_zone;
select * from tweets_clean;
exit
;
select country from tweets_clean where id = '330044004693598208'
;
use sagnik2u6057;
describe tweets_clean
;
select country from tweets_clean where id = '330044004693598208';
ADD JAR hdfs:///data/hive/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar;
SET hive.support.sql11.reserved.keywords=false;
select country from tweets_clean where id = '330044004693598208';
create view l1 as select id, words from tweets_raw lateral view explode(sentences(lower(text))) dummy as words;
describe tweets_raw
;
create view l2 as select id, word from l1 lateral view explode( words ) dummy as word ;
create view l3 as select 
id, 
l2.word,
case d.polarity 
when  'negative' then -1
when 'positive' then 1 
else 0 end as polarity 
from l2 left outer join dictionary d on l2.word = d.word;
describe l3;
select polarity from l3 where word = 'crushes';
create table tweets_sentiment stored as orc as select 
id, 
case 
when sum( polarity ) > 0 then 'positive' 
when sum( polarity ) < 0 then 'negative'  
else 'neutral' end as sentiment 
from l3 group by id;
select sentiment from l3 where id = '330043911940751360';
select sentiment from tweets_sentiment where id = '330043911940751360';
CREATE TABLE tweetsbi 
STORED AS ORC
AS
SELECT 
t.*,
s.sentiment 
FROM tweets_clean t LEFT OUTER JOIN tweets_sentiment s on t.id = s.id;
describe tweetssbi;
describe tweetsbi;
select country, sentiment from tweetsbi where id = '330043924896968707'
'
;
select country, sentiment from tweetsbi where id = '330043924896968707';
use sqoop_testing;
select * from widgets;
exit
;
use sg;
CREATE TABLE sales_test(widget_id INT, qty INT,
street STRING, city STRING, state STRING,
zip INT, sale_date STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
use sagnik2u6057;
CREATE TABLE sales_test(widget_id INT, qty INT,
street STRING, city STRING, state STRING,
zip INT, sale_date STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
LOAD DATA INPATH "sales.log" INTO TABLE sales_test;
LOAD DATA LOCAL INPATH '/data/hive/sales.log' INTO TABLE sales_test;
LOAD DATA INPATH '/data/hive/sales.log' INTO TABLE sales_test;
LOAD DATA LOCAL INPATH '/data/hive/sales.log' INTO TABLE sales_test;
LOAD DATA LOCAL INPATH sales.log' INTO TABLE sales_test;
LOAD DATA LOCAL INPATH 'sales.log' INTO TABLE sales_test;
select * from sales_test;
exit;
